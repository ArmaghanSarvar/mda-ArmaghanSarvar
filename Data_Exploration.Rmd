---
title: "Mini Data-Analysis Milestone 1"
author: "Armaghan Sarvar"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Loading the the Necessary Packages

```{r}
library(datateachr)  # provides 7 semi-tidy datasets
library(tidyverse)  # provides data analysis libraries
```


## 1.1 Choosing four datasets from the `datateachr` package

Here, the four datasets that I have chosen for analysi are listed and briefly described.

1. `cancer_sample`: Acquired courtesy of UCI Machine Learning Repository. It is reported to have 569 rows and 32 columns.
2. `steam_games`: Acquired courtesy of Kaggle. It is reported to have 40833 rows and 21 columns.
3. `vancouver_trees`: Acquired courtesy of The City of Vancouver’s Open Data Portal. It is reported to have 146611 rows and 20 columns.
4. `apt_buildings`: Acquired courtesy of The City of Toronto’s Open Data Portal. It is reported to have 3455 rows and 37 columns.


## 1.2 In the following parts, the four chosen datasets will be explored. 
More specifically, the `dplyr` package will be used to help us find out at least 3 attributes about each dataset. 

### Dataset 1

```{r}
cancer_sample
```

* Class Type
```{r}
class(cancer_sample)
```


* Dimension of the dataset
```{r}
dim(cancer_sample)
```


* Variables (features) of the dataset
```{r}
names(cancer_sample)
```

* Overall view of the data frame

```{r}
summary(cancer_sample)
```


* See the unique values in the "diagnosis" column
```{r}
unique(cancer_sample$diagnosis)
```


* Counting the number of samples for each diagnosis result
```{r}
cancer_sample %>%
  group_by(diagnosis) %>%
  summarize(n())
```


### Dataset 2


```{r}
steam_games
```

* Class Type
```{r}
class(steam_games)
```


* Dimension of the dataset
```{r}
dim(steam_games)
```


* Variables (features) of the dataset
```{r}
names(steam_games)
```


* Overall view of the data frame

```{r}
summary(steam_games)
```


* See the unique values in the "types" column
```{r}
unique(steam_games$types)
```


* Counting the number of samples for each type reported
```{r}
steam_games %>%
  group_by(types) %>%
  summarize(n())
```



### Dataset 3


```{r}
vancouver_trees
```

* Class Type
```{r}
class(vancouver_trees)
```


* Dimension of the dataset
```{r}
dim(vancouver_trees)
```


* Variables (features) of the dataset
```{r}
names(vancouver_trees)
```


* Overall view of the data frame

```{r}
summary(vancouver_trees)
```


* See the unique values in the "street_side_name" column
```{r}
unique(vancouver_trees$street_side_name)
```


* Counting the number of samples for each street_side_name reported
```{r}
vancouver_trees %>%
  group_by(street_side_name) %>%
  summarize(n())
```


### Dataset 4


```{r}
apt_buildings
```

* Class Type
```{r}
class(apt_buildings)
```


* Dimension of the dataset
```{r}
dim(apt_buildings)
```


* Variables (features) of the dataset
```{r}
names(apt_buildings)
```


* Overall view of the data frame

```{r}
summary(apt_buildings)
```


* See the unique values in the "heating_type" column
```{r}
unique(apt_buildings$heating_type)
```


* Counting the number of samples for each heating_type reported
```{r}
apt_buildings %>%
  group_by(heating_type) %>%
  summarize(n())
```


## 1.3 Narrowing down top 2 datasets
Based on the exploration done in the previous part (section 1.2), I found `cancer_sample` and `steam_games` most fascinating ones.

* `cancer_samples`: 
1. First of all, I find the application and usage of this dataset in healthcare highly interesting and important. 
By analyzing this dataset, we can predict whether a possible detected tumour is malignant or benign based on its features.
2. As the code is shown in the previous section, the number of samples for each diagnosis result (357	and	212) are close to each other, which says we have a balanced dataset.
3. We do not have any NaN values in the diagnosis column.
4. Many quantitative values are present in the dataset which makes statistical analysis in terms of relation between different values more meaningful.

* `steam_games`: 
1. In this dataset, features and their values are human-readable and no expertise is needed for understanding them.
2. The application of marketing analysis that can be performed on it is highly interesting.
3. As the code is shown in the previous section, the number of samples for each of the "app" and "bundle" type values is high enough which can help us analyze the differences between the two, for example based on the reviews recorded.  
4. Dataset has a "recent_reviews" column, which enables many research questions about the data. In the following, the possible analysis is shown:

```{r}
nrow(steam_games %>%
  filter(str_detect(recent_reviews, "Positive")))
```
```{r}
nrow(steam_games %>%
  filter(str_detect(recent_reviews, "Negative")))
```

```{r}
nrow(steam_games %>%
  filter(str_detect(recent_reviews, "Mixed")))
```



## 1.4 Choosing the final dataset

My final choice in dataset selection would be `cancer_sample`.
A possible research question I'm interested in answering is: 
** How can we diagnose cancer having different quantitative variables and characteristics of images from breast tumors? **



# Task 2: Exploring the chosen dataset

## 2.1 
In this section, 4 exercises will be conducted to help me dive deeper into the data. These exercises are listed below:

1. Plotting the histogram of the numeric variable "perimeter_mean":

```{r}
cancer_sample %>%
  ggplot(aes(x=perimeter_mean)) + 
  geom_histogram(aes(y=..density..), bins=20, colour="blue", fill="cyan") + geom_density(fill="grey", alpha=0.6)
```
As we can in the above plot, the frequencies of the "perimeter_mean" column values form a left-skewed curve. 

```{r}
ggplot(cancer_sample) +
    geom_jitter(aes(x = perimeter_mean, y = diagnosis), colour="blue", alpha = 0.6)
```
As shown in the above plot, we can have a general separation of Benign and Malignant diagnosis values based on the values of the "perimeter_mean" feature. As perimeter_mean increases, more samples are Malignant.

2. Investigating how many missing values there are per variable. (And finding a way to plot this!)

```{r}
cancer_sample %>%
  select(everything()) %>%  
  summarise_all(funs(sum(is.na(.))))
```

As it can be seen, there are no missing values in this dataset at all.
Plotting the above calculation:
 
```{r}
my_res <- (cancer_sample %>% 
  summarise_all(funs(sum(is.na(.))))) 
 
null_counts <- c(my_res) 
 
plot(1:length(null_counts), null_counts, xaxt = "n", xlab='Variables', ylab='Missing Values', type = 'p') 
axis(1, at=1:length(null_counts), labels=names(cancer_sample))
```


3. Exploring the relationship between 2 variables in a plot. 

```{r}
cancer_sample %>% 
  ggplot(aes(symmetry_mean, concavity_mean, color = diagnosis)) +
  geom_point(alpha = 0.6)
```
In the above scatter plot, the relationship between symmetry and concavity of the cell nuclei is represented. the samples are differentiated based on Malignant vs. Benign diagnosis values.

4. Using a boxplot to look at the frequency of different observations within two variables. 

```{r}
ggplot(cancer_sample, aes(x = diagnosis, y = perimeter_mean)) +
  geom_boxplot()
ggplot(cancer_sample, aes(x = diagnosis, y = symmetry_mean)) +
  geom_boxplot()
```
As shown in the above box plot, we can see the distribution of each of the "perimeter_mean" and "symmetry_mean" features based on the observation of samples being Malignant or Benign. This helps us compare how the different feature values and their data percentiles and averages are regarding the diagnosis. 


## 2.2 Explanation of the chosen exercises

* Exercise 1: 
1. It makes sense to look at the distribution of any of the columns provided in the dataset. This is because we want to see the shape of the distribution, especially when determining whether the output of a process is distributed approximately normally.
2. Each numeric variable has an effect on the `diagnosis` outcome, and we can compare the scatter plot of the feature values across the values of the diagnosis column.

* Exercise 2: It is important to check for missing values in a dataset, since the existence of these values can effect both statistical analysis and future model building on the data. I was able to make sure that fortunately, there was no unrecorded value in the `cancer_sample` dataset. 

* Exercise 3: I decided to do this exercise because I believe exploring the relationship between 2 variables helps us measure the strength of the positive/negative relationship between two features and compute their association. A high correlation points to a strong relationship between the two variables, while a low correlation means that the variables are weakly related. In the extracted plot we gained an idea of this relationship regarding the diagnosis binary values.

* Exercise 4: I decided to look at the frequencies of variables by using a boxplot because I believe a box plot is easy to read, it can summarize data regarding different observations and display the results in a single graph. Since the boxplot is a standardized way of displaying the distribution of data based on minimum, first quartile, median, third quartile, and maximum, it tells us about the outliers and also allows for comparison of data for more effective decision-making. 


# Task 3: Research Questions
1. Can we predict a diagnosis as malignant or benign based on the provided features from nuclei images?
2. How is the distribution of each feature value considering the samples being malignant or benign?
3. What are the statistical measurements of two features when compared to each other among malignant and benign diagnoses? For example, what are the values of the mean, median and standard deviation of concavity_mean vs. symmetry_mean among malignant diagnoses?
4. Which features have a more signifact effect on the samples being classified as malignant or benign? In other words, which columns can we omit and still have a deterministic diagnosis prediction on input samples and which columns play an important role in separating the data values?

